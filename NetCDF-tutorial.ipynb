{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploring netCDFs** \n",
    "adapted from [Katy Abbot](https://github.com/amnh/BridgeUP-STEM-Oceans-Six/blob/master/jupyter-notebooks/netCDF_practice.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://camo.githubusercontent.com/77e36a1f8169f7da010f7c1615fe39ab88f190ea/687474703a2f2f6465736b746f702e6172636769732e636f6d2f656e2f6172636d61702f31302e332f6d616e6167652d646174612f6e65746364662f475549442d44383732413443332d373439452d343135392d413643302d4642364433423437433544382d7765622e676966)\n",
    "What are netCDF files? The acronym stands for Network Common Data Form, and they're a way of formatting data that makes it easy for other scientists to share and read data on different computers, with different operating systems, with different software etc... without running into issues or struggling to understand someone else's work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF files are in what we call an array-oriented dataset. Data is stored in arrays, which are like grids, and can be accessed by selecting the appropriate row and column. Here's an example of a 2D array:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://camo.githubusercontent.com/b525fcfb6792a87d5a15b0b1c52fc39aff739722/68747470733a2f2f7777772e6479636c617373726f6f6d2e636f6d2f696d6167652f746f7069632f632f32642d61727261792f32642d61727261792e6a7067\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With netCDF files, our rows, columns, and other indices are called dimensions, and they can take values such as latitude, longitude and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://simulatingcomplexity.files.wordpress.com/2014/11/netcdf-file-structure.png\" width=\"400\"/>\n",
    "\n",
    "Let's try to explore this file format with an actual file. Make sure you have the file sea_velocity_19930101.nc in your GitHub repository. This is a dataset of velocity geostrophic velocities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to explore the file in Terminal.\n",
    "\n",
    "* In Terminal, type **ncdump -h sea_velocity_19930101.nc** to see all the headers for the file. \n",
    "\n",
    "* Type **ncdump -v \"header title\"** to see the data in the file under that header.\n",
    "    \n",
    "* Try exploring the files by searching different headers (time, lattitude, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to explore using python:  Our first step is to import netCDF4.Dataset, one of the main tools we use for viewing netCDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset #import Dataset from the netCDF4 package\n",
    "dataset = Dataset(r'/Users/helenfellow/Documents/InternGit/ocean-ml/sea_velocity_19930101.nc') #replace with pathname for your computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
      "    _NCProperties: version=1|netcdflibversion=4.4.1|hdf5libversion=1.8.18\n",
      "    Conventions: CF-1.6\n",
      "    Metadata_Conventions: Unidata Dataset Discovery v1.0\n",
      "    cdm_data_type: Grid\n",
      "    comment: Sea Surface Height measured by Altimetry and derived variables\n",
      "    contact: http://climate.copernicus.eu/c3s-user-service-desk\n",
      "    creator_email: http://climate.copernicus.eu/c3s-user-service-desk\n",
      "    creator_name: Copernicus Climate Change Service (C3S)\n",
      "    creator_url: http://climate.copernicus.eu\n",
      "    date_created: 2019-06-12T17:08:33Z\n",
      "    date_issued: 2019-06-12T17:08:33Z\n",
      "    date_modified: 2019-06-12T17:08:33Z\n",
      "    geospatial_lat_max: 89.875\n",
      "    geospatial_lat_min: -89.875\n",
      "    geospatial_lat_resolution: 0.25\n",
      "    geospatial_lat_units: degrees_north\n",
      "    geospatial_lon_max: 359.875\n",
      "    geospatial_lon_min: 0.125\n",
      "    geospatial_lon_resolution: 0.25\n",
      "    geospatial_lon_units: degrees_east\n",
      "    geospatial_vertical_max: 0.0\n",
      "    geospatial_vertical_min: 0.0\n",
      "    geospatial_vertical_positive: down\n",
      "    geospatial_vertical_resolution: point\n",
      "    geospatial_vertical_units: m\n",
      "    history: 2019-06-12 17:08:34Z: Creation\n",
      "    institution: CLS, CNES\n",
      "    keywords: Oceans > Ocean Topography > Sea Surface Height\n",
      "    keywords_vocabulary: NetCDF COARDS Climate and Forecast Standard Names\n",
      "    license: http://climate.copernicus.eu/c3s-user-service-desk\n",
      "    platform: Jason-3, Sentinel-3A\n",
      "    processing_level: L4\n",
      "    product_version: 2019\n",
      "    project: Copernicus Climate Change Service (C3S)\n",
      "    references: http://climate.copernicus.eu\n",
      "    software_version: 6.3_DUACS_DT2018_baseline\n",
      "    source: Altimetry measurements\n",
      "    ssalto_duacs_comment: The reference mission used for the altimeter inter-calibration processing is Topex/Poseidon between 1993-01-01 and 2002-04-23, Jason-1 between 2002-04-24 and 2008-10-18, OSTM/Jason-2 between 2008-10-19 and 2016-06-25, Jason-3 since 2016-06-25.\n",
      "    standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table v37\n",
      "    summary: SSALTO/DUACS Delayed-Time Level-4 sea surface height and derived variables measured by multi-satellite altimetry observations over Global Ocean.\n",
      "    time_coverage_duration: P1D\n",
      "    time_coverage_end: 2019-01-12T00:00:00Z\n",
      "    time_coverage_resolution: P1D\n",
      "    time_coverage_start: 2019-01-12T00:00:00Z\n",
      "    title: DT merged two satellites Global Ocean Gridded SSALTO/DUACS Sea Surface Height L4 product and derived variables\n",
      "    History: Translated to CF-1.0 Conventions by Netcdf-Java CDM (CFGridWriter2)\n",
      "Original Dataset = dataset-duacs-rep-global-merged-twosat-phy-l4; Translation Date = 2019-10-01T16:46:27.755Z\n",
      "    dimensions(sizes): time(1), latitude(720), longitude(1440)\n",
      "    variables(dimensions): int32 \u001b[4mugos\u001b[0m(time,latitude,longitude), float32 \u001b[4mtime\u001b[0m(time), float32 \u001b[4mlatitude\u001b[0m(latitude), float32 \u001b[4mlongitude\u001b[0m(longitude), int32 \u001b[4mvgos\u001b[0m(time,latitude,longitude), int32 \u001b[4mvgosa\u001b[0m(time,latitude,longitude), int32 \u001b[4merr\u001b[0m(time,latitude,longitude), int32 \u001b[4mugosa\u001b[0m(time,latitude,longitude)\n",
      "    groups: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset) #What output do you see when you run this command?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've now created an object, called dataset, that we can use to access different aspects of the file. We'll use the dot notation (i.e. dataset.blahblahblah) to access different parts of the data.\n",
    "\n",
    "Let's find out more about this dataset. We'll look at the \"metadata,\" which is basically data about the data. \n",
    "\n",
    "Scientists use this to explain how the data was acquired or made, how old it is, who to contact with questions etc. First, we'll look at the dataset's \"global attributes,\" which can be accessed by calling ncattrs (shorthand for netcdf attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'_NCProperties',\n",
       " u'Conventions',\n",
       " u'Metadata_Conventions',\n",
       " u'cdm_data_type',\n",
       " u'comment',\n",
       " u'contact',\n",
       " u'creator_email',\n",
       " u'creator_name',\n",
       " u'creator_url',\n",
       " u'date_created',\n",
       " u'date_issued',\n",
       " u'date_modified',\n",
       " u'geospatial_lat_max',\n",
       " u'geospatial_lat_min',\n",
       " u'geospatial_lat_resolution',\n",
       " u'geospatial_lat_units',\n",
       " u'geospatial_lon_max',\n",
       " u'geospatial_lon_min',\n",
       " u'geospatial_lon_resolution',\n",
       " u'geospatial_lon_units',\n",
       " u'geospatial_vertical_max',\n",
       " u'geospatial_vertical_min',\n",
       " u'geospatial_vertical_positive',\n",
       " u'geospatial_vertical_resolution',\n",
       " u'geospatial_vertical_units',\n",
       " u'history',\n",
       " u'institution',\n",
       " u'keywords',\n",
       " u'keywords_vocabulary',\n",
       " u'license',\n",
       " u'platform',\n",
       " u'processing_level',\n",
       " u'product_version',\n",
       " u'project',\n",
       " u'references',\n",
       " u'software_version',\n",
       " u'source',\n",
       " u'ssalto_duacs_comment',\n",
       " u'standard_name_vocabulary',\n",
       " u'summary',\n",
       " u'time_coverage_duration',\n",
       " u'time_coverage_end',\n",
       " u'time_coverage_resolution',\n",
       " u'time_coverage_start',\n",
       " u'title',\n",
       " u'History']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.ncattrs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at one of these, type in the name of the dataset variable, and add a period (.) and the name of the attribute you want to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.875\n",
      "P1D\n",
      "http://climate.copernicus.eu/c3s-user-service-desk\n"
     ]
    }
   ],
   "source": [
    "print(dataset.geospatial_lat_max)\n",
    "print(dataset.time_coverage_duration)\n",
    "print(dataset.contact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the dimensions of the dataset by calling **dataset.dimensions.** Notice that the output is a dictionary. We can see the \"keys,\" or dimension names, with **dataset.dimensions.keys()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(u'time', <type 'netCDF4._netCDF4.Dimension'>: name = 'time', size = 1\n",
      "), (u'latitude', <type 'netCDF4._netCDF4.Dimension'>: name = 'latitude', size = 720\n",
      "), (u'longitude', <type 'netCDF4._netCDF4.Dimension'>: name = 'longitude', size = 1440\n",
      ")])\n",
      "[u'time', u'latitude', u'longitude']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.dimensions)\n",
    "print(dataset.dimensions.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see a specific dimension, you can do so by adding brackets and the dimension name in quotes. i.e. **dataset.dimensions['time']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9b7d4e92eaf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ugos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(dataset.dimensions['ugos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know the dimensions of this file, try to draw a sketch, like the images at the start of this Jupyter notebook, that show the possible dimensions and how they relate to each other. Don't worry about \"bnds\" for now.\n",
    "We can also access the variables of our dataset by typing dataset.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OrderedDict([(u'ugos', <type 'netCDF4._netCDF4.Variable'>\n",
      "int32 ugos(time, latitude, longitude)\n",
      "    _FillValue: -2147483647\n",
      "    coordinates: time latitude longitude \n",
      "    grid_mapping: crs\n",
      "    long_name: Absolute geostrophic velocity: zonal component\n",
      "    scale_factor: 0.0001\n",
      "    standard_name: surface_geostrophic_eastward_sea_water_velocity\n",
      "    units: m/s\n",
      "    _ChunkSizes: [ 1 50 50]\n",
      "unlimited dimensions: \n",
      "current shape = (1, 720, 1440)\n",
      "filling on), (u'time', <type 'netCDF4._netCDF4.Variable'>\n",
      "float32 time(time)\n",
      "    axis: T\n",
      "    calendar: gregorian\n",
      "    long_name: Time\n",
      "    standard_name: time\n",
      "    units: days since 1950-01-01 00:00:00\n",
      "    _ChunkSizes: 1\n",
      "    _CoordinateAxisType: Time\n",
      "unlimited dimensions: \n",
      "current shape = (1,)\n",
      "filling on, default _FillValue of 9.96920996839e+36 used\n",
      "), (u'latitude', <type 'netCDF4._netCDF4.Variable'>\n",
      "float32 latitude(latitude)\n",
      "    axis: Y\n",
      "    bounds: lat_bnds\n",
      "    long_name: Latitude\n",
      "    standard_name: latitude\n",
      "    units: degrees_north\n",
      "    valid_max: 89.875\n",
      "    valid_min: -89.875\n",
      "    _ChunkSizes: 50\n",
      "    _CoordinateAxisType: Lat\n",
      "unlimited dimensions: \n",
      "current shape = (720,)\n",
      "filling on, default _FillValue of 9.96920996839e+36 used\n",
      "), (u'longitude', <type 'netCDF4._netCDF4.Variable'>\n",
      "float32 longitude(longitude)\n",
      "    axis: X\n",
      "    bounds: lon_bnds\n",
      "    long_name: Longitude\n",
      "    standard_name: longitude\n",
      "    units: degrees_east\n",
      "    valid_max: 359.875\n",
      "    valid_min: 0.125\n",
      "    _ChunkSizes: 50\n",
      "    _CoordinateAxisType: Lon\n",
      "unlimited dimensions: \n",
      "current shape = (1440,)\n",
      "filling on, default _FillValue of 9.96920996839e+36 used\n",
      "), (u'vgos', <type 'netCDF4._netCDF4.Variable'>\n",
      "int32 vgos(time, latitude, longitude)\n",
      "    _FillValue: -2147483647\n",
      "    coordinates: time latitude longitude \n",
      "    grid_mapping: crs\n",
      "    long_name: Absolute geostrophic velocity: meridian component\n",
      "    scale_factor: 0.0001\n",
      "    standard_name: surface_geostrophic_northward_sea_water_velocity\n",
      "    units: m/s\n",
      "    _ChunkSizes: [ 1 50 50]\n",
      "unlimited dimensions: \n",
      "current shape = (1, 720, 1440)\n",
      "filling on), (u'vgosa', <type 'netCDF4._netCDF4.Variable'>\n",
      "int32 vgosa(time, latitude, longitude)\n",
      "    _FillValue: -2147483647\n",
      "    comment: The geostrophic velocity anomalies are referenced to the [1993, 2012] period\n",
      "    coordinates: time latitude longitude \n",
      "    grid_mapping: crs\n",
      "    long_name: Geostrophic velocity anomalies: meridian component\n",
      "    scale_factor: 0.0001\n",
      "    standard_name: surface_geostrophic_northward_sea_water_velocity_assuming_sea_level_for_geoid\n",
      "    units: m/s\n",
      "    _ChunkSizes: [ 1 50 50]\n",
      "unlimited dimensions: \n",
      "current shape = (1, 720, 1440)\n",
      "filling on), (u'err', <type 'netCDF4._netCDF4.Variable'>\n",
      "int32 err(time, latitude, longitude)\n",
      "    _FillValue: -2147483647\n",
      "    comment: The formal mapping error represents a purely theoretical mapping error. It mainly traduces errors induced by the constellation sampling capability and consistency with the spatial/temporal scales considered, as described in Le Traon et al (1998) or Ducet et al (2000)\n",
      "    coordinates: time latitude longitude \n",
      "    grid_mapping: crs\n",
      "    long_name: Formal mapping error\n",
      "    scale_factor: 0.0001\n",
      "    units: m\n",
      "    _ChunkSizes: [ 1 50 50]\n",
      "unlimited dimensions: \n",
      "current shape = (1, 720, 1440)\n",
      "filling on), (u'ugosa', <type 'netCDF4._netCDF4.Variable'>\n",
      "int32 ugosa(time, latitude, longitude)\n",
      "    _FillValue: -2147483647\n",
      "    comment: The geostrophic velocity anomalies are referenced to the [1993, 2012] period\n",
      "    coordinates: time latitude longitude \n",
      "    grid_mapping: crs\n",
      "    long_name: Geostrophic velocity anomalies: zonal component\n",
      "    scale_factor: 0.0001\n",
      "    standard_name: surface_geostrophic_eastward_sea_water_velocity_assuming_sea_level_for_geoid\n",
      "    units: m/s\n",
      "    _ChunkSizes: [ 1 50 50]\n",
      "unlimited dimensions: \n",
      "current shape = (1, 720, 1440)\n",
      "filling on)]), '\\n \\n')\n",
      "[u'ugos', u'time', u'latitude', u'longitude', u'vgos', u'vgosa', u'err', u'ugosa']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.variables, \"\\n \\n\")  #\"\\n\" creates a new empty line so you can separate your output\n",
    "\n",
    "print(dataset.variables.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables have a lot more information, right? Let's look at just one variable: latitude. Inspect it by typing **dataset.variables['latitude']**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<type 'netCDF4._netCDF4.Variable'>\n",
       "int32 ugos(time, latitude, longitude)\n",
       "    _FillValue: -2147483647\n",
       "    coordinates: time latitude longitude \n",
       "    grid_mapping: crs\n",
       "    long_name: Absolute geostrophic velocity: zonal component\n",
       "    scale_factor: 0.0001\n",
       "    standard_name: surface_geostrophic_eastward_sea_water_velocity\n",
       "    units: m/s\n",
       "    _ChunkSizes: [ 1 50 50]\n",
       "unlimited dimensions: \n",
       "current shape = (1, 720, 1440)\n",
       "filling on"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.variables['ugos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different attributes can you identify? (standard_name, long_name, cell_methods, _FillValue, missing_value, original_name, original_units, history, current shape). Look at the second line. It gives the name of the variable, and it also lists three names in parentheses after it. What do you think those names signify?\n",
    "\n",
    "We can access any one of these attributes by calling it directly. Just add a period at the end of your call to a variable and add in the attribute name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lon_bnds\n",
      "Longitude\n"
     ]
    }
   ],
   "source": [
    "print(dataset.variables['longitude'].bounds)\n",
    "print(dataset.variables['longitude'].long_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis\n",
      "X\n",
      "bounds\n",
      "lon_bnds\n",
      "long_name\n",
      "Longitude\n",
      "standard_name\n",
      "longitude\n",
      "units\n",
      "degrees_east\n",
      "valid_max\n",
      "359.875\n",
      "valid_min\n",
      "0.125\n",
      "_ChunkSizes\n",
      "50\n",
      "_CoordinateAxisType\n",
      "Lon\n"
     ]
    }
   ],
   "source": [
    "for attr in dataset.variables['longitude'].ncattrs(): #ncattrs is a shorthand way of saying the attributes of a netCDF file\n",
    "    print(attr)\n",
    "    print(getattr(dataset.variables['longitude'], attr))  #getattr is a function that takes a variable and an attribute name and returns its value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be wondering: Where's the actual data?? So far, we've learning about what variables and dimensions are in this dataset, but we haven't actually seen any numbers or values.\n",
    "\n",
    "Let's look at the latitude and longitude values. To do so, you'll call on a variable (i.e. dataset.variables['tos'], as above), but you'll add [:] after it to tell the computer that you want to see the numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('latitude: ', masked_array(data=[-89.875, -89.625, -89.375, -89.125, -88.875, -88.625,\n",
      "                   -88.375, -88.125, -87.875, -87.625, -87.375, -87.125,\n",
      "                   -86.875, -86.625, -86.375, -86.125, -85.875, -85.625,\n",
      "                   -85.375, -85.125, -84.875, -84.625, -84.375, -84.125,\n",
      "                   -83.875, -83.625, -83.375, -83.125, -82.875, -82.625,\n",
      "                   -82.375, -82.125, -81.875, -81.625, -81.375, -81.125,\n",
      "                   -80.875, -80.625, -80.375, -80.125, -79.875, -79.625,\n",
      "                   -79.375, -79.125, -78.875, -78.625, -78.375, -78.125,\n",
      "                   -77.875, -77.625, -77.375, -77.125, -76.875, -76.625,\n",
      "                   -76.375, -76.125, -75.875, -75.625, -75.375, -75.125,\n",
      "                   -74.875, -74.625, -74.375, -74.125, -73.875, -73.625,\n",
      "                   -73.375, -73.125, -72.875, -72.625, -72.375, -72.125,\n",
      "                   -71.875, -71.625, -71.375, -71.125, -70.875, -70.625,\n",
      "                   -70.375, -70.125, -69.875, -69.625, -69.375, -69.125,\n",
      "                   -68.875, -68.625, -68.375, -68.125, -67.875, -67.625,\n",
      "                   -67.375, -67.125, -66.875, -66.625, -66.375, -66.125,\n",
      "                   -65.875, -65.625, -65.375, -65.125, -64.875, -64.625,\n",
      "                   -64.375, -64.125, -63.875, -63.625, -63.375, -63.125,\n",
      "                   -62.875, -62.625, -62.375, -62.125, -61.875, -61.625,\n",
      "                   -61.375, -61.125, -60.875, -60.625, -60.375, -60.125,\n",
      "                   -59.875, -59.625, -59.375, -59.125, -58.875, -58.625,\n",
      "                   -58.375, -58.125, -57.875, -57.625, -57.375, -57.125,\n",
      "                   -56.875, -56.625, -56.375, -56.125, -55.875, -55.625,\n",
      "                   -55.375, -55.125, -54.875, -54.625, -54.375, -54.125,\n",
      "                   -53.875, -53.625, -53.375, -53.125, -52.875, -52.625,\n",
      "                   -52.375, -52.125, -51.875, -51.625, -51.375, -51.125,\n",
      "                   -50.875, -50.625, -50.375, -50.125, -49.875, -49.625,\n",
      "                   -49.375, -49.125, -48.875, -48.625, -48.375, -48.125,\n",
      "                   -47.875, -47.625, -47.375, -47.125, -46.875, -46.625,\n",
      "                   -46.375, -46.125, -45.875, -45.625, -45.375, -45.125,\n",
      "                   -44.875, -44.625, -44.375, -44.125, -43.875, -43.625,\n",
      "                   -43.375, -43.125, -42.875, -42.625, -42.375, -42.125,\n",
      "                   -41.875, -41.625, -41.375, -41.125, -40.875, -40.625,\n",
      "                   -40.375, -40.125, -39.875, -39.625, -39.375, -39.125,\n",
      "                   -38.875, -38.625, -38.375, -38.125, -37.875, -37.625,\n",
      "                   -37.375, -37.125, -36.875, -36.625, -36.375, -36.125,\n",
      "                   -35.875, -35.625, -35.375, -35.125, -34.875, -34.625,\n",
      "                   -34.375, -34.125, -33.875, -33.625, -33.375, -33.125,\n",
      "                   -32.875, -32.625, -32.375, -32.125, -31.875, -31.625,\n",
      "                   -31.375, -31.125, -30.875, -30.625, -30.375, -30.125,\n",
      "                   -29.875, -29.625, -29.375, -29.125, -28.875, -28.625,\n",
      "                   -28.375, -28.125, -27.875, -27.625, -27.375, -27.125,\n",
      "                   -26.875, -26.625, -26.375, -26.125, -25.875, -25.625,\n",
      "                   -25.375, -25.125, -24.875, -24.625, -24.375, -24.125,\n",
      "                   -23.875, -23.625, -23.375, -23.125, -22.875, -22.625,\n",
      "                   -22.375, -22.125, -21.875, -21.625, -21.375, -21.125,\n",
      "                   -20.875, -20.625, -20.375, -20.125, -19.875, -19.625,\n",
      "                   -19.375, -19.125, -18.875, -18.625, -18.375, -18.125,\n",
      "                   -17.875, -17.625, -17.375, -17.125, -16.875, -16.625,\n",
      "                   -16.375, -16.125, -15.875, -15.625, -15.375, -15.125,\n",
      "                   -14.875, -14.625, -14.375, -14.125, -13.875, -13.625,\n",
      "                   -13.375, -13.125, -12.875, -12.625, -12.375, -12.125,\n",
      "                   -11.875, -11.625, -11.375, -11.125, -10.875, -10.625,\n",
      "                   -10.375, -10.125,  -9.875,  -9.625,  -9.375,  -9.125,\n",
      "                    -8.875,  -8.625,  -8.375,  -8.125,  -7.875,  -7.625,\n",
      "                    -7.375,  -7.125,  -6.875,  -6.625,  -6.375,  -6.125,\n",
      "                    -5.875,  -5.625,  -5.375,  -5.125,  -4.875,  -4.625,\n",
      "                    -4.375,  -4.125,  -3.875,  -3.625,  -3.375,  -3.125,\n",
      "                    -2.875,  -2.625,  -2.375,  -2.125,  -1.875,  -1.625,\n",
      "                    -1.375,  -1.125,  -0.875,  -0.625,  -0.375,  -0.125,\n",
      "                     0.125,   0.375,   0.625,   0.875,   1.125,   1.375,\n",
      "                     1.625,   1.875,   2.125,   2.375,   2.625,   2.875,\n",
      "                     3.125,   3.375,   3.625,   3.875,   4.125,   4.375,\n",
      "                     4.625,   4.875,   5.125,   5.375,   5.625,   5.875,\n",
      "                     6.125,   6.375,   6.625,   6.875,   7.125,   7.375,\n",
      "                     7.625,   7.875,   8.125,   8.375,   8.625,   8.875,\n",
      "                     9.125,   9.375,   9.625,   9.875,  10.125,  10.375,\n",
      "                    10.625,  10.875,  11.125,  11.375,  11.625,  11.875,\n",
      "                    12.125,  12.375,  12.625,  12.875,  13.125,  13.375,\n",
      "                    13.625,  13.875,  14.125,  14.375,  14.625,  14.875,\n",
      "                    15.125,  15.375,  15.625,  15.875,  16.125,  16.375,\n",
      "                    16.625,  16.875,  17.125,  17.375,  17.625,  17.875,\n",
      "                    18.125,  18.375,  18.625,  18.875,  19.125,  19.375,\n",
      "                    19.625,  19.875,  20.125,  20.375,  20.625,  20.875,\n",
      "                    21.125,  21.375,  21.625,  21.875,  22.125,  22.375,\n",
      "                    22.625,  22.875,  23.125,  23.375,  23.625,  23.875,\n",
      "                    24.125,  24.375,  24.625,  24.875,  25.125,  25.375,\n",
      "                    25.625,  25.875,  26.125,  26.375,  26.625,  26.875,\n",
      "                    27.125,  27.375,  27.625,  27.875,  28.125,  28.375,\n",
      "                    28.625,  28.875,  29.125,  29.375,  29.625,  29.875,\n",
      "                    30.125,  30.375,  30.625,  30.875,  31.125,  31.375,\n",
      "                    31.625,  31.875,  32.125,  32.375,  32.625,  32.875,\n",
      "                    33.125,  33.375,  33.625,  33.875,  34.125,  34.375,\n",
      "                    34.625,  34.875,  35.125,  35.375,  35.625,  35.875,\n",
      "                    36.125,  36.375,  36.625,  36.875,  37.125,  37.375,\n",
      "                    37.625,  37.875,  38.125,  38.375,  38.625,  38.875,\n",
      "                    39.125,  39.375,  39.625,  39.875,  40.125,  40.375,\n",
      "                    40.625,  40.875,  41.125,  41.375,  41.625,  41.875,\n",
      "                    42.125,  42.375,  42.625,  42.875,  43.125,  43.375,\n",
      "                    43.625,  43.875,  44.125,  44.375,  44.625,  44.875,\n",
      "                    45.125,  45.375,  45.625,  45.875,  46.125,  46.375,\n",
      "                    46.625,  46.875,  47.125,  47.375,  47.625,  47.875,\n",
      "                    48.125,  48.375,  48.625,  48.875,  49.125,  49.375,\n",
      "                    49.625,  49.875,  50.125,  50.375,  50.625,  50.875,\n",
      "                    51.125,  51.375,  51.625,  51.875,  52.125,  52.375,\n",
      "                    52.625,  52.875,  53.125,  53.375,  53.625,  53.875,\n",
      "                    54.125,  54.375,  54.625,  54.875,  55.125,  55.375,\n",
      "                    55.625,  55.875,  56.125,  56.375,  56.625,  56.875,\n",
      "                    57.125,  57.375,  57.625,  57.875,  58.125,  58.375,\n",
      "                    58.625,  58.875,  59.125,  59.375,  59.625,  59.875,\n",
      "                    60.125,  60.375,  60.625,  60.875,  61.125,  61.375,\n",
      "                    61.625,  61.875,  62.125,  62.375,  62.625,  62.875,\n",
      "                    63.125,  63.375,  63.625,  63.875,  64.125,  64.375,\n",
      "                    64.625,  64.875,  65.125,  65.375,  65.625,  65.875,\n",
      "                    66.125,  66.375,  66.625,  66.875,  67.125,  67.375,\n",
      "                    67.625,  67.875,  68.125,  68.375,  68.625,  68.875,\n",
      "                    69.125,  69.375,  69.625,  69.875,  70.125,  70.375,\n",
      "                    70.625,  70.875,  71.125,  71.375,  71.625,  71.875,\n",
      "                    72.125,  72.375,  72.625,  72.875,  73.125,  73.375,\n",
      "                    73.625,  73.875,  74.125,  74.375,  74.625,  74.875,\n",
      "                    75.125,  75.375,  75.625,  75.875,  76.125,  76.375,\n",
      "                    76.625,  76.875,  77.125,  77.375,  77.625,  77.875,\n",
      "                    78.125,  78.375,  78.625,  78.875,  79.125,  79.375,\n",
      "                    79.625,  79.875,  80.125,  80.375,  80.625,  80.875,\n",
      "                    81.125,  81.375,  81.625,  81.875,  82.125,  82.375,\n",
      "                    82.625,  82.875,  83.125,  83.375,  83.625,  83.875,\n",
      "                    84.125,  84.375,  84.625,  84.875,  85.125,  85.375,\n",
      "                    85.625,  85.875,  86.125,  86.375,  86.625,  86.875,\n",
      "                    87.125,  87.375,  87.625,  87.875,  88.125,  88.375,\n",
      "                    88.625,  88.875,  89.125,  89.375,  89.625,  89.875],\n",
      "             mask=False,\n",
      "       fill_value=1e+20,\n",
      "            dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print(\"latitude: \", dataset.variables['latitude'][:]) #print the latitude values, and then add a line break to distinguish from longitude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ‘‰netCDF file cheat sheetðŸ‘ˆ\n",
    "[This tutorial](http://www.ceda.ac.uk/static/media/uploads/ncas-reading-2015/10_read_netcdf_python.pdf) was written in Python 2.7, so the print command is slightly different, but it's a helpful read to understand how these files work.\n",
    "\n",
    "Addditionally:\n",
    "1. Import the tools to open a dataset: **from netCDF4 import Dataset**\n",
    "2. Open a dataset: **dataset = Dataset('filename.nc')**\n",
    "3. View the dataset's attributes: **dataset.ncattrs()**\n",
    "4. Access a specific attribute: **dataset.attribute_name**\n",
    "5. View the dataset's dimensions: **dataset.dimensions**\n",
    "6. View a specific dimension: **dataset.dimensions[ 'name of dimension' ]**\n",
    "7. View the dataset's variables: **dataset.variables**\n",
    "8. View a specific variable: **dataset.variables[ 'name of variable' ]**\n",
    "9. See a variable's values: **dataset.variables[ 'name of variable' ][ : ]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
